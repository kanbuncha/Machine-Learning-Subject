{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "t_nI2LkOtQkp"
   },
   "outputs": [],
   "source": [
    "def search_parameter(model):\n",
    "    p = {\n",
    "        # 'activation':['relu', 'sigmoid', 'tanh', 'softmax'],\n",
    "         'optimizer': ['SGD','Adam'],\n",
    "         'losses': ['categorical_crossentropy'],\n",
    "         'batch_size': [8, 16, 20, 40, 60, 80, 100],\n",
    "         'epochs': [10, 50, 100]\n",
    "         }\n",
    "\n",
    "    def cnn_model(X_train, y_train, x_val, y_val, params):\n",
    "        model = Sequential()\n",
    "        model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(X_train.shape[1:]), padding='same'))\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Conv2D(64, kernel_size=(3, 3), activation='relu', padding='same'))\n",
    "        model.add(Conv2D(128, kernel_size=(3, 3), activation='relu', padding='same'))\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(128 , activation='relu' ))\n",
    "        model.add(Dense(y_train.shape[1], activation='sigmoid'))\n",
    "        optimizer = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, amsgrad=False)\n",
    "        model.compile( loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "        out = model.fit(X_train, y_train, batch_size=params['batch_size'], epochs=params['epochs'], validation_data=[X_test, y_test], verbose=0)\n",
    "        return out, model\n",
    "\n",
    "    def lstm_model(X_train, y_train, x_val, y_val, params):\n",
    "        model = Sequential()\n",
    "        model.add(LSTM(32, input_shape=(X_2d_train.shape[1:]) ))\n",
    "        model.add(Dense(y_2d_train.shape[1], activation='sigmoid'))\n",
    "        optimizer = Adam(lr=0.003, beta_1=0.9, beta_2=0.999, amsgrad=False)\n",
    "        model.compile( loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "        out = model.fit( X_2d_train, y_2d_train, batch_size=params['batch_size'], validation_data=(X_2d_valid, y_2d_valid), epochs=params['epochs'], verbose=0)\n",
    "        return out, model\n",
    "\n",
    "    if model == 'cnn' :\n",
    "      scan_object = ta.Scan(X_train, y_train, model=cnn_model, params=p, experiment_name='cnn', fraction_limit=0.1)\n",
    "    else :\n",
    "      scan_object = ta.Scan(X_2d_train, y_2d_train, model=lstm_model, params=p, experiment_name='lstm', fraction_limit=0.1)\n",
    "\n",
    "    return scan_object\n",
    "\n",
    "def cnn_model(optimizer, losses) :\n",
    "  model = Sequential()\n",
    "  model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(X_train.shape[1:]), padding='same'))\n",
    "  model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "  model.add(BatchNormalization())\n",
    "  model.add(Dropout(0.25))\n",
    "\n",
    "  model.add(Conv2D(64, kernel_size=(3, 3), activation='relu', padding='same'))\n",
    "  model.add(BatchNormalization())\n",
    "\n",
    "  model.add(Conv2D(128, kernel_size=(3, 3), activation='relu', padding='same'))\n",
    "  model.add(BatchNormalization())\n",
    "\n",
    "  model.add(Flatten())\n",
    "  model.add(Dense(128 , activation='relu' ))\n",
    "  model.add(Dense(y_train.shape[1], activation='sigmoid'))\n",
    "  model.compile( loss=losses, optimizer=optimizer, metrics=['accuracy'])\n",
    "  return model\n",
    "\n",
    "def lstm_model(optimizer, losses) :\n",
    "  model = Sequential()\n",
    "  model.add(LSTM(32, input_shape=(X_2d_train.shape[1:]) ))\n",
    "  model.add(Dense(y_2d_train.shape[1], activation='sigmoid'))\n",
    "  model.compile( loss=losses, optimizer=optimizer, metrics=['accuracy'])\n",
    "  return model\n",
    "\n",
    "def show_search_res(scan, model) :\n",
    "  # use Scan object as input\n",
    "  analyze_object = ta.Analyze(scan)\n",
    "  print(analyze_object.data)\n",
    "  print('=================================================')\n",
    "\n",
    "  # get the highest result for any metric\n",
    "  print('Low validate loss : ', analyze_object.high('val_accuracy'))\n",
    "  print('=================================================')\n",
    "\n",
    "  # get the round with the best result\n",
    "  print('\\nindex of best result :', analyze_object.rounds2high('val_accuracy'))\n",
    "  print('=================================================')\n",
    "\n",
    "  # evaluae with k fold\n",
    "  e = ta.Evaluate(scan)\n",
    "  model_evaluate = list()\n",
    "  if model == 'lstm' :\n",
    "    xx = X_2d_train\n",
    "    yy = y_2d_train\n",
    "  else :\n",
    "    xx = X_train\n",
    "    yy = y_train\n",
    "  for i in range(len(analyze_object.data)) :\n",
    "    evaluate = e.evaluate(xx, yy, folds=10, metric='val_accuracy', task='multi_label', model_id=i)\n",
    "    model_evaluate.append(np.array(evaluate).mean())\n",
    "  print('evaluate with kfold', model_evaluate)\n",
    "  print('=================================================')\n",
    "\n",
    "  # get the best paramaters\n",
    "  print('\\nbest parameters :')\n",
    "  print(analyze_object.best_params('val_accuracy', ['acc', 'loss', 'val_loss']))\n",
    "  analyze_object.plot_line('val_accuracy')\n",
    "  return analyze_object, model_evaluate\n",
    "\n",
    "\n",
    "scan = search_parameter('cnn')\n",
    "print(scan.details)\n",
    "print('=================================================')\n",
    "analyze_object_cnn, model_cnn_evaluate = show_search_res(scan, 'cnn')\n",
    "\n",
    "scan = search_parameter('lstm')\n",
    "print(scan.details)\n",
    "print('=================================================')\n",
    "analyze_object_lstm, model_lstm_evaluate = show_search_res(scan, 'lstm')\n",
    "\n",
    "cnn_best_params = analyze_object_cnn.data.iloc[analyze_object_cnn.rounds2high('val_accuracy'), :]\n",
    "print('CNN best score : ', model_cnn_evaluate[analyze_object_cnn.rounds2high('val_accuracy')])\n",
    "print('CNN best parameters : \\n', cnn_best_params)\n",
    "\n",
    "print('==================================')\n",
    "\n",
    "lstm_best_params = analyze_object_lstm.data.iloc[analyze_object_lstm.rounds2high('val_accuracy'), :]\n",
    "print('LSTM best score : ', model_lstm_evaluate[analyze_object_cnn.rounds2high('val_accuracy')])\n",
    "print('LSTM best parameters : \\n', lstm_best_params)\n",
    "\n",
    "\n",
    "# save\n",
    "cnn_best_params.to_csv(root_dir + '/cnn_best_params.csv')\n",
    "lstm_best_params.to_csv(root_dir + '/lstm_best_params.csv')\n",
    "\n",
    "model = cnn_model(cnn_best_params['optimizer'], cnn_best_params['losses'])\n",
    "model.summary()\n",
    "history = model.fit(X_train, y_train, batch_size=cnn_best_params['batch_size'], validation_data=(X_valid, y_valid), epochs=cnn_best_params['epochs'], verbose=1)\n",
    "\n",
    "# ใช้โมเดลที่สอนจากพารามิเตอร์ที่ดีที่สุดมา predict ข้อมูล ชุด x_test\n",
    "y_prediction = model.predict(X_test)\n",
    "y_pred_single = [np.argmax(p) for p in y_prediction]\n",
    "y_test_single=[np.argmax(p) for p in y_test]\n",
    "\n",
    "# คำนวณค่าตัววัดประสิทธิภาพของการทำนายจากโมเดล CNN\n",
    "\n",
    "print(classification_report(y_test_single, y_pred_single))\n",
    "\n",
    "conf_mat = confusion_matrix(y_test_single, y_pred_single)\n",
    "plt.figure(figsize = (10, 7))\n",
    "ax = sns.heatmap(conf_mat, annot=True, fmt=\"d\", xticklabels='0 1 2 3 4'.split(), yticklabels='0 1 2 3 4'.split(), cmap=\"Blues\")\n",
    "bottom, top = ax.get_ylim()\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "model = lstm_model(lstm_best_params['optimizer'], lstm_best_params['losses'])\n",
    "model.summary()\n",
    "history = model.fit(X_2d_train, y_2d_train, batch_size=lstm_best_params['batch_size'], validation_data=(X_2d_valid, y_2d_valid), epochs=lstm_best_params['epochs'], verbose=1)\n",
    "\n",
    "y_prediction = model.predict(X_2d_test)\n",
    "y_pred_single = [np.argmax(p) for p in y_prediction]\n",
    "y_test_single = [np.argmax(p) for p in y_2d_test]\n",
    "\n",
    "# คำนวณค่าตัววัดประสิทธิภาพของการทำนายจากโมเดล CNN\n",
    "\n",
    "print(classification_report(y_test_single, y_pred_single))\n",
    "\n",
    "conf_mat = confusion_matrix(y_test_single, y_pred_single)\n",
    "plt.figure(figsize = (10, 7))\n",
    "ax = sns.heatmap(conf_mat, annot=True, fmt=\"d\", xticklabels='0 1 2 3 4'.split(), yticklabels='0 1 2 3 4'.split(), cmap=\"Blues\")\n",
    "bottom, top = ax.get_ylim()\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Lab3",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
