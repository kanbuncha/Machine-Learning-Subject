{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 563
    },
    "colab_type": "code",
    "id": "j2Gqu4CA2iH2",
    "outputId": "e4e489de-c6a3-422d-af00-36005b657a05"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 3, 4, 32)          320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 1, 2, 32)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 1, 2, 32)          128       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1, 2, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 1, 2, 64)          18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 1, 2, 64)          256       \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 1, 2, 128)         73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 1, 2, 128)         512       \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 5)                 645       \n",
      "=================================================================\n",
      "Total params: 127,109\n",
      "Trainable params: 126,661\n",
      "Non-trainable params: 448\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# ตอนที่ 2 การทดลองสร้าง สอน และ ทดสอบโมเดล เพื่อดูค่าความแม่นยำเบื้องต้นของแต่ละโมเดล (CNN, LSTM)\n",
    "# CNN\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(X_train.shape[1:]), padding='same'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu', padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Conv2D(128, kernel_size=(3, 3), activation='relu', padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128 , activation='relu' ))\n",
    "model.add(Dense(y_train.shape[1], activation='sigmoid'))\n",
    "model.summary()\n",
    "\n",
    "# optimizer = SGD(lr=0.01, decay=1e-6, momentum=0.8, nesterov=True)\n",
    "optimizer = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, amsgrad=False)\n",
    "model.compile( loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X_train, y_train, batch_size=16, validation_data=(X_valid, y_valid), epochs=100, verbose=1)\n",
    "\n",
    "# predict CNN\n",
    "y_prediction = model.predict(X_test)\n",
    "y_pred_single = [np.argmax(p) for p in y_prediction]\n",
    "y_test_single=[np.argmax(p) for p in y_test]\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(2, figsize=(8, 6))\n",
    "\n",
    "acc = history.history['accuracy']\n",
    "loss = history.history['loss']\n",
    "ax1.plot(acc, label=model)\n",
    "ax2.plot(loss, label=model)\n",
    "    \n",
    "ax1.set_ylabel('Training accuracy')\n",
    "ax2.set_ylabel('Training loss')\n",
    "ax2.set_xlabel('epochs')\n",
    "plt.show()\n",
    "\n",
    "# คำนวณค่าตัววัดประสิทธิภาพของการทำนายจากโมเดล CNN \n",
    "print(classification_report(y_test_single, y_pred_single))\n",
    "\n",
    "conf_mat = confusion_matrix(y_test_single, y_pred_single)\n",
    "plt.figure(figsize = (10, 7))\n",
    "ax = sns.heatmap(conf_mat, annot=True, fmt=\"d\", xticklabels='0 1 2 3 4'.split(), yticklabels='0 1 2 3 4'.split(), cmap=\"Blues\")\n",
    "bottom, top = ax.get_ylim()\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# LSTM\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(32, input_shape=(X_2d_train.shape[1:]) ))\n",
    "\n",
    "\n",
    "# model.add(Dropout(0.25))\n",
    "\n",
    "# model.add(Dropout(0.25))\n",
    "model.add(Dense(y_2d_train.shape[1], activation='sigmoid'))\n",
    "model.summary()\n",
    "\n",
    "optimizer = Adam(lr=0.003, beta_1=0.9, beta_2=0.999, amsgrad=False)\n",
    "model.compile( loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "history = model.fit( X_2d_train, y_2d_train, batch_size=16, validation_data=(X_2d_valid, y_2d_valid), epochs=100)\n",
    "\n",
    "# predict LSTM\n",
    "y_prediction = model.predict(X_2d_test)\n",
    "y_pred_single = [np.argmax(p) for p in y_prediction]\n",
    "y_test_single = [np.argmax(p) for p in y_2d_test]\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(2, figsize=(8, 6))\n",
    "\n",
    "acc = history.history['accuracy']\n",
    "loss = history.history['loss']\n",
    "ax1.plot(acc, label=model)\n",
    "ax2.plot(loss, label=model)\n",
    "    \n",
    "ax1.set_ylabel('Training accuracy')\n",
    "ax2.set_ylabel('Training loss')\n",
    "ax2.set_xlabel('epochs')\n",
    "#ax1.legend()\n",
    "#ax2.legend()\n",
    "plt.show()\n",
    "\n",
    "# คำนวณค่าตัววัดประสิทธิภาพของการทำนายจากโมเดล LSTM\n",
    "print(classification_report(y_test_single, y_pred_single))\n",
    "\n",
    "conf_mat = confusion_matrix(y_test_single, y_pred_single)\n",
    "plt.figure(figsize = (10, 7))\n",
    "ax = sns.heatmap(conf_mat, annot=True, fmt=\"d\", xticklabels='0 1 2 3 4'.split(), yticklabels='0 1 2 3 4'.split(), cmap=\"Blues\")\n",
    "bottom, top = ax.get_ylim()\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Lab3",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
